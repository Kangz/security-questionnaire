<h1>Self-Review Questionnaire: Security and Privacy</h1>
<pre class="metadata">
Status: DREAM
ED: https://w3ctag.github.io/security-questionnaire/
Shortname: security-privacy-questionnaire
Level: 1
Editor: Lukasz Olejnik, Independent researcher, me@lukaszolejnik.com
Former Editor: Mike West, Google Inc., mkwst@google.com
Group: tag
Indent: 2
Abstract:
  This document provides a points to help in considering the privacy impact of
  a new feature or specification. The questions are meant to be useful when
  considering the security and privacy aspects of a new feature or
  specification. The respective points should be addressed by representatives
  (e.g. editors) behind the new proposal or a feature. Given the variety and
  nature of specifications, it is likely that the listed questions will not be
  comprehensive in a way enabling to reason about the full privacy impact.
  It is nonetheless the aim to present the questions as a useful point, helping
  to consider security and privacy at the start of work on a new feature.

  It is not meant as a "security checklist", nor does an editor or group’s use
  of this questionnaire obviate the editor or group’s responsibility to obtain
  "wide review" of a specification security and privacy properties before
  publication. Furthermore, the filled questionnaire should not be understood
  as security and privacy considerations, although part of the answers may be
  relevant in drafting the considerations.

Version History: https://github.com/w3ctag/security-questionnaire/commits/master/index.src.html
!Bug Reports: <a href="https://github.com/w3ctag/security-questionnaire/issues/new">via the w3ctag/security-questionnaire repository on GitHub</a>
</pre>

<!-- Big Text: Intro -->
<section>
  <h2 id="intro">Introduction</h2>

  New web features are what makes the web live and stronger. When working on
  them - planning, drafting, implementing - there is always a risk of
  unforeseen security and privacy implications. This may happen due to the
  details of the new feature, some of its part(s), or the unforeseen
  interactions with other features.

  The challenges in standardization of web mechanisms are unique, as they
  relate to all the user agents. In that, the descriptions, protocols and
  algorithms need to be considered strictly, since the mechanisms are typically
  foreseen for a broad adoption by vendors with large user base. This unique
  position is a <em>challenge</em>, because inefficiencies and inadequacies
  introduced early in the process may propagate - eventually reaching to a
  number of User Agents, and affecting the security and privacy of users on a
  significant scale. However, this position is also an <em>asset</em>, since
  carefully considering the risks and challenges early in the process helps
  ensuring a high quality in terms of security and privacy.

  If a feature is found to introduce undesirable risks, weakness or threats,
  the risk does not only relate to the users and the browsers, but also to the
  web itself. This is because vendors may subsequently choose prioritising the
  protection of users by introducing changes breaking compatibility. In the
  end, the whole web ecosystem may be negatively affected.


  This is why each Working Group needs to consider <em>security and
  privacy</em> <b>by default</b>. This consideration is <b>mandatory</b>.
  Furthermore, assessing the impact of a mechanism on privacy should be done
  from the ground up, during each iteration of the specification. The
  questionnaire here presented is meant as guidelines helping to consider
  security and privacy as early as possible, on the level of Working Group (and
  earlier even, at the level of Community Groups).

  Providing adequate and informative answers to the questions, such as
  providing context, or explaining the reasoning behind certain choices, will
  also help in a wide security and privacy review performed later on, within
  the W3C review proces, and beyond.

  This document encourages early review by posing a number of questions that
  you as an individual reader/writer/contributor of a specification can ask —
  and that working groups and spec editors need to consider, prior asking for a
  more formal review. The intent is to highlight areas which have historically
  had interesting implications on a user’s security or privacy, and thereby to
  focus the editor, working group attention, and reviewers' attention on areas
  that might previously have been overlooked.</p>

  The audience of this document is general:

  *   The editors and contributors who are responsible for the development of
      the feature,
  *   The W3C TAG, who receive the questionnaire along with the request, and in
      line with the W3C Process,
  *   External audience (developers, designers, etc.) wanting to understand the
      possible security and privacy implications.

<h2 id="threats">How To Use The Questionnaire</h2>

  Starting to think about possible implications to security and privacy early
  in the project is the best approach. This approach helps providing the
  initial baseline  features are later checked against. Update the document
  (the security and privacy questionnaire) upon any significant changes to the
  specification. When requesting a Technical Architecture Group review, include
  the filled questionnaire, along with the description of changes or
  observations made during the design. This allows external reviewers
  understand the rationale, as well as thechallenges and evolution of the
  feature, with respect to security and privacy.

  It is understandable that developers may not always be have the necessary
  data to see the broader picture and possible implications, for example in
  relation to other existing web functionalities. The answers to the
  questionnaire are meant as help and input for people who may nonetheless make
  security and privacy remarks, or the assessment.

</section>

<!-- Big Text: Threats -->
<section>
  <h2 id="threats">Threat Models</h2>

  To consider security and privacy it is convenient to think in terms of threat
  models - in a way illuminating the possible risks.

  <h3 id="passive-network">Passive Network Attackers</h3>

  A <dfn>passive network attacker</dfn> has read-access to the bits going over
  the wire between users and the servers they're communicating with. She can't
  <em>modify</em> the bytes, but she can collect and analyze them.

  Due to the decentralized nature of the internet, and the general level of
  interest in user activity, it's reasonable to assume that practically every
  unencrypted bit that's bouncing around the network of proxies, routers, and
  servers you're using right now is being read by someone. It's equally likely
  that some of these attackers are doing their best to understand the encrypted
  bits as well (though that requires significantly more effort).

  *   The IETF's "Pervasive Monitoring Is an Attack" document [[RFC7258]] is
      useful reading, outlining some of the impacts on privacy that this
      assumption entails.

  *   Governments aren't the only concern; your local coffee shop is likely to
      be gathering information on its customers, your ISP at home is likely to
      be doing the same.

  <h3 id="active-network">Active Network Attackers</h3>

  An <dfn>active network attacker</dfn> has both read- and write-access to the
  bits going over the wire between users and the servers they're communicating
  with. She can collect and analyze data, but also modify it in-flight,
  injecting and manipulating JavaScript and HTML at will. This is more common
  than you might expect, for both benign and malicious purposes:

  *   ISPs and caching proxies regularly cache and compress images before
      delivering them to users in an effort to reduce data usage. This can be
      especially useful for users on low-bandwidth, high-latency devices like
      phones.

  *   ISPs also regularly inject JavaScript [[COMCAST]] and other identifiers
      [[VERIZON]] for less benign purposes.

  *   If your ISP is willing to modify substantial amounts of traffic flowing
      through it for profit, it's difficult to believe that state-level
      attackers will remain passive.

  <h3 id="sop-violations">Same-Origin Policy Violations</h3>

  The <dfn>same-origin policy</dfn> is the cornerstone of security on the web;
  one origin should not have direct access to another origin's data (the policy
  is more formally defined in Section 3 of [[RFC6454]]). A corollary to this
  policy is that an origin should not have direct access to data that isn't
  associated with <em>any</em> origin: the contents of a user's hard drive,
  for instance. Various kinds of attacks bypass this protection in one way or
  another. For example:

  *   <dfn local-lt="XSS">Cross-site scripting attacks</dfn> involve an
      attacker tricking an origin into executing attacker-controlled code in
      the context of a target origin.

  *   <dfn local-lt="CSRF">Cross-site request forgery attacks</dfn> trick
      user agents into exerting a user's ambient authority on sites where
      they've logged in by submitting requests on their behalf.

  *   Data leakage occurs when bits of information are inadvertantly made
      available cross-origin, either explicitly via CORS headers [[CORS]],
      or implicitly, via side-channel attacks like [[TIMING]].
  *

  <h3 id="third-party-tracking">Third-Party Tracking</h3>

  Third-party tracking may occur when content from one origin is embedded or
  otherwise injected in another origin in a way that information may be
  accessed, revealed, queried or reasoned by third-party. This third-party may
  be a script injected on a first-party site

  *   The simplest example is injecting a link to a site that behaves
      differently under specific condition, for example based on the fact that
      user is or is not logged to the site. This may reveal that the user has
      an account on a site.

  <h3 id="legitimate-misuse">Legitimate Misuse</h3>

  Even when powerful features are made available to developers, it does not
  mean that all the uses should always be a good idea, or justified; in fact,
  data privacy regulations around the world may even put limits on certain uses
  of data. In the context of first party, a legitimate website is potentially
  able to interact with powerful features to learn about the user behavior or
  habits. For example:

  *   Tracking the user while browsing the website via mechanisms such as mouse
      move tracking

  *   Behavioral profiling of the user based on the usage patterns

  *   Accessing powerful features enabling to reason about the user system,
      himself or the user surrounding, such as a webcam, Web Bluetooth or
      sensors

  This point is admittedly different from others - and underlines that even if
  something may be possible, it does not mean it should always be done,
  including the need for considering a privacy impact assessment or even an
  ethical assessment. When designing a specification with security and privacy
  in mind, all both use and misuse cases should be in scope.


</section>

<!-- Big Text: Questions -->
<section>
  <h2 id="questions">Questions to Consider</h2>

  <h3 id="purpose">
    What information might this feature expose to Web sites or other parties,
    and for what purposes is that exposure necessary?”
  </h3>

  Just because information can be exposed to the web doesn’t mean that it
  should be. How does exposing this information to an origin benefit a user?
  Is the benefit outweighed by the potential risks?  If so, how?

  <h3 id="minimum-data">
    Is this specification exposing the minimum amount of information necessary
    to power the feature?
  </h3>

  Regardless of what data is being exposed, is the specification exposing the
  bare minimum necessary to achieve the desired use cases?  If not, why not and
  why expose the additional information?

  <h3 id="personal-data">
    Does this specification deal with personal information or
    personally-identifiable information or information derived thereof?
  </h3>

  Personally information is data about a user (home address) or information
  that could be used to identify a user (alias or email address).  This is
  distinct from personally identifiable information (PII), as the exact
  definition of what’s considered PII varies from jurisdiction to jurisdiction.

  If the specification under consideration exposes personal information or PII
  or their derivatives that could still identify an individual to the web, it’s
  important to consider ways to mitigate the obvious impacts. For instance:

  *   A feature which uses biometric data (fingerprints or retina scans)
      should refuse to expose the raw data to the web, instead using the raw
      data only to unlock some origin-specific and ephemeral secret and
      transmitting that secret instead.
  *   Including a factor of user mediation should be considered, in order to
      ensure that no data is exposed without a user’s explicit choice (and
      hopefully understanding). One way to achieve this may be the use of
      Permission API [PERMISSIONS], or additional dialogs like in Payment
      Request API [PAYMENT-REQUEST-API]

  <h3 id="sensitive-data">
    Does this specification deal with sensitive information?
  </h3>

  Just because data is not personally information or PII, that does not mean
  that it is not sensitive information; moreover, whether any given information
  is sensitive may vary from user to user.  Data to consider if sensitive
  includes: financial data, credentials, health information, location, or
  credentials. When this data is exposed to the web, steps should be taken to
  mitigate the risk of exposing it; for example:

  *   Credential Management [[CREDENTIAL-MANAGEMENT]] allows sites to request
      a user's credentials from a user agent's password manager in order to
      sign the user in quickly and easily. This opens the door for abuse, as
      a single XSS vulnerability could expose user data trivially to
      JavaScript. The Credential Managerment API mitigates
      the risk by offering the username and password as only an opaque
      <code>FormData</code> object which cannot be directly read by JavaScript
      and strongly suggests that authors use Content Security Policy [[CSP]]
      with resonable <code>connect-src</code> and <code>form-action</code>
      values to further mitigate the risk of exfiltration.
  *   Geolocation information can serve many use cases at a much less granular
      precision than the user agent can offer. For instance, a resturaunt
      recommendation can be generated by asking for a user’s city-level
      location rather than a position accurate to the centimeter.
  *   A Geofencing proposal [GEOFENCING] ties itself to service workers and
      therefore to encrypted and authenticated origins.

  <h3 id="persistent-origin-specific-state">
    Does this specification introduce new state for an origin that persists
    across browsing sessions?
  </h3>

  Allowing an origin to persist data on a user’s device across browsing
  sessions introduces the risk that this state may be used to track a user
  without their knowledge or control, either in a first party or third party
  contexts.  New state persistence mechanisms should not be introduced without
  mitigations to prevent it from being used to track users across domains or
  without control over clearing this state.  And, are there specific caches
  that a user agent should specially consider?

  For example:

  *   Service Worker [[SERVICE-WORKERS]] intercept all requests made by an
      origin, allowing sites to function perfectly even when offline. A
      maliciously-injected service worker, however, would be devastating (as
      documented in that spec's
      <a href="http://www.w3.org/TR/service-workers/#security-considerations">
      security considerations section</a>). They mitigate the risks an
      <a>active network attacker</a> or <a>XSS</a> vulnerability present by
      requiring an encrypted and authenticated connection in order to register
      a service worker.

  *   Platform-specific DRM implementations might expose origin-specific
      information in order to help identify users and determine whether they
      ought to be granted access to a specific piece of media. These kinds of
      identifiers should be carefully evaluated to determine how abuse can be
      mitigated; identifiers which a user cannot easily change are very
      valuable from a tracking perspective, and protecting the identifiers from
      an active network attacker is an important concern.

  *   Cookies, <code>ETag</code>, <code>Last Modified</code>, <code>Local
      Storage</code>, <code>Indexed DB</code>, etc. all allow an origin to
      store information about a user, and retrieve it later, directly or
      indirectly. User agents mitigate the risk that these kinds of storage
      mechanisms will form a persistent identifier by offering users the
      ability to wipe out the data contained in these types of storage.

  <h3 id="underlying-platform-data">
    Does this specification expose information to an origin that originates
    from the underlying platform and is consistent across origins, including
    user configurations or sensors?
  </h3>

  When a specification exposes specific information about a host to an origin,
  if that information changes rarely and is not variable across origins, then
  it can be used to uniquely identify a user across two origins — either
  directly because any given piece of information is unique or because the
  combination of disparate pieces of information are unique and can be used to
  form a fingerprint [[ DOTY-FINGERPRINTING ]]. Specifications and user agents
  should treat the risk of fingerprinting by carefully considering the surface
  of available information, and the relative differences between software and
  hardware stacks. Sometimes reducing fingerprintability may as simple as
  ensuring consistency, i.e. ordering the list of fonts, but sometimes may be
  more complex.

  Such information should not be revealed to an origin without a user’s
  knowledge and consent barring mitigations in the specification to prevent the
  information from being uniquely identifying or able to unexpectedly
  exfiltrate data.

  For example:

  *   The <code>GL_RENDERER</code> string exposed by some WebGL implementations
      improves performance in some kinds of applications, but does so at the
      cost of adding persistent state to a user's fingerprint. These kinds of
      device-level details should be carefully weighed to ensure that the costs
      are outweighed by the benefits.

  *   The {{NavigatorPlugins}} list exposed via the DOM practically never
      changes for most users. Some user agents have taken steps to reduce the
      entropy introduced by
      <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=757726">disallowing
      direct enumeration of the plugin list</a>.

  <h3 id="sensor-data">
    Does this specification allow an origin access to sensors on a user’s
    device?
  </h3>

  Information from sensors may serve as a fingerprinting vector across origins.
  In addition, sensor also reveals something about my device or environment and
  that fact might be what is sensitive.  In addition, as technology advances,
  mitigations in place at the time a specification is written may have to be
  reconsidered as the threat landscape changes.

  These are not theoretical attacks, for example:
  *   As gryoscopes advanced, their sampling rate had to be lowered to
      prevent them from being used as a microphone as one such example
      [[ GYROSPEECHRECOGNITION ]].
  *   ALS sensors could allowed for an attacker to exfiltrate whether or not a
      user had visited given links [[ OLEJNIK-ALS ]].
  *   Even relatively short lived data, like the battery status, may be able to
      serve as an identifier if misued/abused [[ OLEJNIK-BATTERY ]].

  <h3 id="other-data">
    What data does this specification expose to an origin?  Please also
    document what data is identical to data exposed by other features, in the
    same or different contexts.
  </h3>

  As noted above in [[#sop-violations]], the <a>same-origin policy</a> is an
  important security barrier that new features need to carefully consider.
  If a specification exposes details about another origin's state, or allows
  POST or GET requests to be made to another origin, the consequences can be
  severe.

  *   Content Security Policy [[CSP]] unintentionally exposed redirect targets
      cross-origin by allowing one origin to infer details about another origin
      through violation reports (see [[HOMAKOV]]). The working group eventually
      mitigated the risk by reducing a policy's granularity after a redirect.

  *   Beacon [[BEACON]] allows an origin to send POST requests to an endpoint
      on another origin. They decided that this feature didn't add any new
      attack surface above and beyond what normal form submission entails, so
      no extra mitigation was necessary.

  <h3 id="string-to-script">
    Does this specification enable new script execution/loading mechanisms?
  </h3>

  * HTML Imports [[HTML-IMPORTS]] create a new script-loading mechanism, using
    <{link}> rather than <{script}>, which might be easy to overlook when
    evaluating an application's attack surface. The working group notes this
    risk, and ensured that they required reasonable interactions with Content
    Security Policy's <code>script-src</code> directive.

  * New string-to-script mechanism? (e.g. `eval()` or `setTimeout([string], ...)`)

  * What about style?

  <h3 id="remote-device">
    Does this specification allow an origin access to other devices?
  </h3>

  Accessing other devices, both via network connections and via
  direct connection to the user's machine (e.g. via Bluetooth,
  NFC, or USB), could expose vulnerabilities - some of
  these devices were not created with web connectivity in mind and may be inadequately
  hardened against malicious input, or with the use on the web.

  Exposing other devices on a user’s local network also has significant privacy
  risk:
  *   If two user agents have the same devices on their local network, an
      attacker may infer that the two user agents are running on the same host
      or are being used by two separate users who are in the same physical
      location.
  *   Enumerating the devices on a user’s local network provides significant
      entropy that an attacker may use to fingerprint the user agent.
  *   If the specification exposes persistent or long lived identifiers of
      local network devices, that provides attackers with a way to track a user
      over time even if a user takes steps to prevent such tracking (e.g.
      clearing cookies and other stateful tracking mechanisms).
  *   Direct connections might be also be used to bypass security checks that
      other APIs would provide. For example, attackers used the WebUSB API to
      access others sites' crendentials on a hardware security, bypassing
      same-origin checks in an early U2F API. [[ YUBIKEY-ATTACK ]]

  Example mitigations include:
  *   The Network Service Discovery API [[DISCOVERY]] recommends CORS preflights
      before granting access to a device, and requires user agents to involve
      the user with a permission request of some kind. The spec's
      <a href="https://dvcs.w3.org/hg/dap/raw-file/tip/discovery-api/Overview.html#security-and-privacy-considerations">Security
      and privacy considerations"</a> section has more details.

  *   Likewise, the Web Bluetooth [[BLUETOOTH]] has an extensive discussion of
      <a href="https://webbluetoothcg.github.io/web-bluetooth/#security-and-privacy-considerations">"Security
      and privacy considerations"</a>, which is worth reading as an example for
      similar work.

  <h3 id="native-ui">
    Does this specification allow an origin some measure of control over a user
    agent's native UI?
  </h3>

  Features that allow for control over a user agent’s UI (e.g. full screen
  mode) or changes to the underlying system (e.g. installing an ‘app’ on a
  smartphone home screen) may surprise users or obscure security / privacy
  controls.  To the extent that your feature does allow for the changing of a
  user agent’s UI, can it effect security / privacy controls?  What analysis
  confirmed this conclusion?

  <h3 id="temporary-id">
    Does this specification expose temporary identifiers to the web?
  </h3>

  Some identifiers may be difficult to pin-point  but they revolve around
  information that is stable in short-term manner (seconds, minutes, days) and
  may be available to web origins, whether in cross-origin manner or even
  cross-browser manner.

  If a standard exposes a temporary identifier to the web, the identifier
  should be short lived and should rotate on some regular duration to mitigate
  the risk of this identifier being used to track a user over time.  When a
  user clears state in their user agent, these temporary identifiers should be
  cleared to prevent re-correlation of state using a temporary identifier.

  Example temporary identifers include TLS Channel ID, Session Tickets, and
  IPv6 addresses.

  <h3 id="first-third-party">Does this specification distinguish between
    behavior in first-party and third-party contexts?
  </h3>

  The behavior of a feature should be considered not just in the context of its
  being used by a first party origin that a user is visiting but also the
  implications of its being used by an arbitrary third party that the first
  party includes. When developing your specification, consider the implications
  of its use by third party resources on a page and, consider if support for
  use by third party resources should be optional to conform to the
  specification.  If supporting use by third party resources is mandatory for
  conformance, please explain why and what privacy mitigations are in place.
  This is particularly important as user agents may take steps to reduce the
  availability or functionality of certain features to third parties if the
  third parties are found to be abusing the functionality.

  <h3 id="private-browsing">
    How does this specification work in the context of a user agent’s Private \
    Browsing or "incognito" mode?
  </h3>

  Each major user agent implements a private browsing / incognito mode feature
  with significant variation across user agents in threat models,
  functionality, and descriptions to users regarding the protections afforded
  [[ WU-PRIVATE-BROWSING ]].

  One typical commonality across user agent’s private browsing / incognito mode
  features is that they have a set of state than the user agents’ in their
  ‘normal’ mode.

  Does the specification provide information that would allow for the
  correlation of a single user's activity across normal and private browsing /
  incognito modes?  Does the specification result in information being written
  to a user’s host that would persist following a private browsing / incognito
  mode session ending?

  <h3 id="considerations">
    Does this specification have a "Security Considerations" and "Privacy
    Considerations" section?
  </h3>

  Documenting the various concerns and potential abuses in "Security
  Considerations" and "Privacy Considerations" sections of a document is a good
  way to help implementers and web developers understand the risks that a
  feature presents, and to ensure that adequate mitigations are in place.
  If it seems like a feature does not have security or privacy impacts,
  then say so inline in the spec section for that feature:

  <blockquote>
    There are no known security or privacy impacts of this feature.
  </blockquote>

  Saying so explicitly in the specification serves several purposes:
  <ol>
    <li>
      Shows that a spec author/editor has explicitly considered security and
      privacy when designing a feature.
    </li>
    <li>
      Provides some sense of confidence that there might be no such impacts.
    </li>
    <li>
      Challenges security and privacy minded individuals to think of and find
      even the potential for such impacts.
    </li>
    <li>
      Demonstrates the spec author/editor's receptivity to feedback about such
      impacts.
    </li>
    <li>
      Demonstrates a desire that the specification should not be introducing
      security and privacy issues
    </li>
  </ol>

  When saying this, however, the crucial aspect is to actually considering
  security and privacy. All new specifications must have security and privacy
  considerations sections to be considered for wide reviews. Interesting
  features added to the web platform generally often already had security
  and/or privacy impacts.

  <h3 id="relaxed-sop">
    Does this specification allow downgrading default security characteristics?
  </h3>

  *   <code>document.domain</code>
  *   [[CORS]]
  *   [[WEBMESSAGING]]
  *   <code>referrer 'unsafe-always'</code>

  <h3 id="behavioral-monitoring">
    Does this specification allow the persistent monitoring of user behavior?
  </h3>
  Users on the web can be monitored in variaty of means, for example using
  access to sensors potentially providing mobility patterns (e.g.
  accelerator, light sensor, web bluetooth), or directly on the web such as
  the monitoring of mouse movement, which are biometric data conveying rich
  information.

</section>

<section>
  <h2 id="mitigations">
    Mitigation Strategies
  </h2>

  <h3 id="secure-contexts">
    Secure Contexts
  </h3>

  In the presence of an <a>active network attacker</a>, offering a feature to
  an insecure origin is the same as offering that feature to every origin (as
  the attacker can inject frames and code at will). Requiring an encrypted and
  authenticated connection in order to use a feature can mitigate this kind of
  risk.

  <h3 id="user-mediation">
    Explicit user mediation
  </h3>

  If a feature has privacy or security impacts that are endemic to the feature
  itself, then one valid strategy for exposing it to the web is to require user
  mediation before granting an origin access. For instance, [[GEOLOCATION-API]]
  reveals a user's location, and wouldn't be particularly useful if it didn't;
  user agents generally gate access to the feature on a permission prompt which
  the user may choose to accept.

  Designing such prompts is difficult. Choosers are good. Walls of text are bad.

  ISSUE: Bring in some of felt@'s ideas here.

  <h3 id="drop-feature">
    Drop the feature
  </h3>

    The simplest way to mitigate potential negative security or privacy impacts of a feature,
    and even discussing the possibility, is to drop the feature.
    Every feature in a spec should be considered guilty (of harming security and/or privacy) until proven otherwise.

    Every specification should seek to be as small as possible, even if only for the reasons of reducing
    and minimizing security/privacy attack surface(s).

    By doing so we can reduce the overall security (and privacy) attack surface of not only a particular feature,
    but of a module (related set of features), a specification, and the overall web platform.

    Examples

    *   <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1313580%20">Mozilla<a> and <a href="https://bugs.webkit.org/show_bug.cgi?id=164213">WebKit</a> dropped Battery Status API
    *   <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1359076">Mozilla dropped<a> devicelight, deviceproximity and userproximity events

      <h3 id="sanitize-data">
        Sanitize the data handled in the feature
      </h3>

      It is always a good strategy to consider the kinds of data a new feature is processing. For example, new features allowing the readout of data may want to adopt specific privacy strategies such as minimizing the quality of datas (quantization) or reducing the frequency, in line with standard privacy engineering practices. Examples
      *   [BATTERY-STATUS-API] <em>“The user agent should not expose high precision readouts”</em>
      * [SENSORS-API] <em>“Limit maximum sampling frequency”, “Reduce accuracy”</em>


      <h3 id="user-mediation">
        Making a privacy impact assessment
      </h3>

      Some features are potentially supplying very sensitive data, and it is the end-developer,
      system owners, or managers responsibility to realize this and act accordingly in the design of his/her
      system. Some use may warrant conducting as privacy impact assessment, especially when data relating to
      individuals may be processed. Examples.

      *   [GENERIC-SENSORS] advices to consider performing of a privacy impact assessment


</section>

<section>
  <h2 id="howtouse">How to Use the questionnaire</h2>

  To ensure good designs, security and privacy should be considered as early as possible.
  This questionnaire facilitates this and the questions should be considered early in the specification development
  process, kept in mind as it matures, with the answers being updated along the specification evolution.
  This questionnaire should not be used as a “check box" excercise before requesting final publication - acting in
  this manner does not help improve privacy or security on the Web.  Each question needs to be considered and that
  any privacy or security concerns are described, along with a possible mitigation strategy.
  It is not a good approach to provide a one-word answer (“yes” / “no”). Rather, it is expected to include an
  explanatory description. The questions in the questionnaire are more about “why” and “how”, rather than “if”.

  It is expected that a questionnaire must be filled in prior to obtaining a W3C Working Draft status, and prior to requiring a review, along the Privacy by Design principles.
  The questionnaire and its answers should not be included in the specification itself. It is preferable to keep it in a standard and easily available place, with a link available in the TAG repository.

</section>

<pre class="anchors">
urlPrefix: http://www.w3.org/TR/html5/
  type: interface
    urlPrefix: webappapis.html
      text: NavigatorPlugins
</pre>

<pre class="link-defaults">
spec:html5; type:element; text:script
</pre>

<pre class="biblio">
{
  "BLUETOOTH": {
      "href": "https://webbluetoothcg.github.io/web-bluetooth/",
      "title": "Web Bluetooth",
      "publisher": "W3C",
      "authors": [ "Jeffrey Yasskin", "Vincent Scheib" ]
  },
  "BATTERY-STATUS": {
    "href": "https://www.w3.org/TR/battery-status/",
    "title" "Battery Status API",
    "publisher": "W3C",
    "authors": ["Anssi Kostiainen", "Mounir Lamouri"]
  },
  "COMCAST": {
      "href": "http://arstechnica.com/tech-policy/2014/09/why-comcasts-javascript-ad-injections-threaten-security-net-neutrality/",
      "title": "Comcast Wi-Fi serving self-promotional ads via JavaScript injection",
      "publisher": "Ars Technica",
      "authors": [ "David Kravets" ]
  },
  "CREDENTIAL-MANAGEMENT": {
      "href": "https://w3c.github.io/webappsec/specs/credentialmanagement/",
      "title": "Credential Management",
      "publisher": "W3C",
      "authors": [ "Mike West" ]
  },
  "DISCOVERY": {
      "href": "http://dvcs.w3.org/hg/dap/raw-file/tip/discovery-api/Overview.html",
      "title": "Network Service Discovery",
      "authors": [ "Rich Tibbett" ],
      "publisher": "W3C"
  },
  "GEOFENCING": {
      "href": "https://github.com/slightlyoff/Geofencing/blob/master/explainer.md",
      "title": "Geofencing Explained",
      "authors": [ "Alex Russell" ]
  },
  "HOMAKOV": {
      "href": "http://homakov.blogspot.de/2014/01/using-content-security-policy-for-evil.html",
      "title": "Using Content-Security-Policy for Evil",
      "authors": [ "Egor Homakov" ]
  },
  "VERIZON": {
      "href": "http://adage.com/article/digital/verizon-target-mobile-subscribers-ads/293356/",
      "title": "Verizon looks to target its mobile subscribers with ads",
      "publisher": "Advertising Age",
      "authors": [ "Mark Bergen", "Alex Kantrowitz" ]
  },
  "PAYMENT-REQUEST-API": {
    "href": "https://www.w3.org/TR/payment-request/",
    "title" "Payment Request",
    "publisher": "W3C",
    "authors": ["Adrian Bateman", "Zach Koch", "Roy McElmurry", "Domenic Denicola", "Marcos Cáceres"]
  },
  "PERMISSIONS": {
    "href": "https://www.w3.org/TR/permissions/",
    "title" "Permissions API",
    "publisher": "W3C",
    "authors": ["Mounir Lamouri", "Marcos Cáceres", "Jeffrey Yasskin"]
  },
  "PII": {
      "href": "https://en.wikipedia.org/wiki/Personally_identifiable_information",
      "title": "Personally identifiable information",
      "publisher": "Wikipedia"
  },
  "TIMING": {
      "href": "http://www.contextis.com/documents/2/Browser_Timing_Attacks.pdf",
      "title": "Pixel Perfect Timing Attacks with HTML5",
      "authors": [ "Paul Stone" ],
      "publisher": "Context Information Security"
  },
  "RFC6454": {
      "href": "https://tools.ietf.org/html/rfc6454",
      "title": "The Web Origin Concept",
      "authors": [ "Adam Barth" ],
      "publisher": "IETF"
  },
  "RFC7258": {
      "href": "http://tools.ietf.org/html/rfc7258",
      "title": "Pervasive Monitoring Is an Attack",
      "authors": [ "Stephen Farrell", "Hannes Tschofenig" ],
      "publisher": "IETF"
  },
  "FIRST-PARTY-ONLY": {
      "href": "https://tools.ietf.org/html/draft-west-first-party-cookies",
      "title": "'First-Party-Only' Cookies",
      "authors": [ "Mike West" ],
      "publisher": "IETF"
  },
  "YUBIKEY-ATTACK": {
      "href": "https://www.wired.com/story/chrome-yubikey-phishing-webusb/",
      "title": "Chrome Lets Hackers Phish Even 'Unphishable' YubiKey Users",
      "authors": [ "Andy Greenberg" ],
      "publisher": "Wired"
  },
  "AMBIENT-LIGHT-API": {
    "href": "https://www.w3.org/TR/ambient-light/",
    "title" "Ambient Light API",
    "publisher": "W3C",
    "authors": [ "Anssi Kostiainen" ]
  },
  "OLEJNIK-ALS": {
    "href": "https://blog.lukaszolejnik.com/privacy-of-ambient-light-sensors/",
    "title": "Privacy analysis of Ambient Light Sensors",
    "publisher": "Lukasz Olejnik",
    "authors": [ "Lukasz Olejnik" ]
  },
  "OLEJNIK-BATTERY": {
    "href": "https://eprint.iacr.org/2015/616",
    "title": "The leaking battery: A privacy analysis of the HTML5 Battery Status API",
    "publisher": "Cryptology ePrint Archive, Report 2015/616",
    "authors": [ "Lukasz Olejnik", "Gunes Acar", "Claude Castelluccia", "Claudia Diaz"]
  },
  "DOTY-FINGERPRINTING": {
    "href": "https://www.w3.org/TR/fingerprinting-guidance/",
    "title": "Fingerprinting Guidance for Web Specification Authors (Draft)",
    "publisher": "W3C",
    "authors": [ "Nick Doty"]
  },
  "GYROSPEECHRECOGNITION": {
    "href": "https://www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-michalevsky.pdf",
    "title": "Gyrophone: Recognizing Speech from Gyroscope Signals",
    "publisher": "Proceedings of the 23rd USENIX Security Symposium",
    "authors": [ "Yan Michalevsky", "Dan Boneh", "Gabi Nakibly"]
  },
  "WU-PRIVATE-BROWSING":{
    "href": "https://dl.acm.org/citation.cfm?id=3186088",
    "title": "Your Secrets Are Safe: How Browsers' Explanations Impact Misconceptions About Private Browsing Mode",
    "publisher": "WWW '18 Proceedings of the 2018 World Wide Web Conference",
    "authors": [ "Yuxi Wu", "Panya Gupta", "Miranda Wei", "Yasemin Acar", "Sascha Fahl", "Blase Ur"]
  }
}
</pre>
